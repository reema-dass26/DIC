{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca4da65b-48b0-4a14-ae56-6d4b41d6d348",
   "metadata": {},
   "source": [
    "# Step 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6fd6a9e-d67e-4684-bb96-1d644899a365",
   "metadata": {},
   "source": [
    "Importing a bunch of modules, there might be some redundancies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "038c44d3-9c3e-48d1-b1f5-9a5455fc671b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intitializing Scala interpreter ..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Spark Web UI available at http://captain01.os.hpc.tuwien.ac.at:9999/proxy/application_1683456198714_2611\n",
       "SparkContext available as 'sc' (version = 3.2.3, master = yarn, app id = application_1683456198714_2611)\n",
       "SparkSession available as 'spark'\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "import org.apache.spark.ml.feature.StringIndexer\n",
       "import org.apache.spark.ml.feature.{RegexTokenizer, Tokenizer}\n",
       "import org.apache.spark.ml.feature.StopWordsRemover\n",
       "import org.apache.spark.ml.feature.ChiSqSelector\n",
       "import org.apache.spark.ml.feature.ChiSqSelectorModel\n",
       "import org.apache.spark.ml.linalg.Vectors\n",
       "import org.apache.spark.ml.feature.{CountVectorizer, CountVectorizerModel}\n",
       "import org.apache.spark.ml.feature.{HashingTF, IDF, Tokenizer}\n",
       "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
       "import org.json4s._\n",
       "import org.json4s.jackson.JsonMethods._\n",
       "import java.io.{PrintWriter, File, FileOutputStream}\n",
       "import org.apache.spark.ml.feature.Normalizer\n",
       "import org.apache.spark.ml.classification.LinearSVC\n",
       "import org.apache.spark.ml.classification.{LinearSVC, OneVsRest}\n",
       "import org.apache.spa...\n"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.ml.feature.StringIndexer\n",
    "import org.apache.spark.ml.feature.{RegexTokenizer, Tokenizer}\n",
    "import org.apache.spark.ml.feature.StopWordsRemover\n",
    "import org.apache.spark.ml.feature.ChiSqSelector\n",
    "import org.apache.spark.ml.feature.ChiSqSelectorModel\n",
    "import org.apache.spark.ml.linalg.Vectors\n",
    "import org.apache.spark.ml.feature.{CountVectorizer, CountVectorizerModel}\n",
    "import org.apache.spark.ml.feature.{HashingTF, IDF, Tokenizer}\n",
    "import org.apache.spark.ml.{Pipeline, PipelineModel}\n",
    "import org.json4s._\n",
    "import org.json4s.jackson.JsonMethods._\n",
    "import java.io.{ PrintWriter, File, FileOutputStream }\n",
    "import org.apache.spark.ml.feature.Normalizer\n",
    "import org.apache.spark.ml.classification.LinearSVC\n",
    "import org.apache.spark.ml.classification.{LinearSVC, OneVsRest}\n",
    "import org.apache.spark.ml.evaluation.MulticlassClassificationEvaluator\n",
    "\n",
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25c8e12-4886-420e-a53c-ef8396953db2",
   "metadata": {},
   "source": [
    "Data could have been loaded straight into a *dataframe* but since I wanted to be efficient aka. code less, I just copy pasted the data from `Part 1` and used `toDF()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab2c5c74-6a2a-49bd-909f-4880c6f69d14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stopwords: Array[String] = Array(a, aa, able, about, above, absorbs, accord, according, accordingly, across, actually, after, afterwards, again, against, ain, album, album, all, allow, allows, almost, alone, along, already, also, although, always, am, among, amongst, an, and, another, any, anybody, anyhow, anyone, anything, anyway, anyways, anywhere, apart, app, appear, appreciate, appropriate, are, aren, around, as, aside, ask, asking, associated, at, available, away, awfully, b, baby, bb, be, became, because, become, becomes, becoming, been, before, beforehand, behind, being, believe, below, beside, besides, best, better, between, beyond, bibs, bike, book, books, both, brief, bulbs, but, by, c, came, camera, can, cannot, cant, car, case, cause, causes, cd, certain, certainly, changes,...\n"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val stopwords = sc.textFile(\"stopwods.txt\").collect()\n",
    "val rdd = sc.textFile(\"hdfs:///user/dic23_shared/amazon-reviews/full/reviews_devset.json\")\n",
    "val data = rdd.map{row => val json_row = parse(row)\n",
    "(compact(json_row \\ \"category\"),\n",
    " compact(json_row \\ \"reviewText\"))}\n",
    "val reviews = data.toDF(\"category\",\"reviewText\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90567887-42c0-401c-973e-4a7c4a8df2b6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "newReviews: org.apache.spark.sql.DataFrame = [category: string, reviewText: string ... 1 more field]\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val newReviews = new StringIndexer()\n",
    "    .setInputCol(\"category\")\n",
    "    .setOutputCol(\"label\")\n",
    "    .fit(reviews)\n",
    "    .transform(reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d254f2d-415e-4748-b248-01a3f28bfe7e",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2345b550-e3c5-4586-badc-3ff6ceb8e1a5",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f53f939-652b-47b2-866e-169a4c9722be",
   "metadata": {},
   "source": [
    "String cleaning, tokenization, setting to lower case. Even though the pattern looks like regex, it's just the delimiters + a bunch of escapes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c139b51-6b84-47c8-8fbd-a6b642aa4baf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tokenizer: org.apache.spark.ml.feature.RegexTokenizer = RegexTokenizer: uid=regexTok_611423317d6d, minTokenLength=2, gaps=true, pattern=[\\(\\)\\[\\]\\{\\}\\.\\!\\?,;:\\+\\='\\-\\_\\\"`~#@&*\\%€$§/\\\\1234567890\t\\s+], toLowercase=true\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val tokenizer = new RegexTokenizer()\n",
    "            .setInputCol(\"reviewText\")\n",
    "            .setOutputCol(\"terms\")\n",
    "            .setPattern(\"[\\\\(\\\\)\\\\[\\\\]\\\\{\\\\}\\\\.\\\\!\\\\?,;:\\\\+\\\\='\\\\-\\\\_\\\\\\\"`~#@&*\\\\%€$§/\\\\\\\\1234567890\\t\\\\s+]\")\n",
    "            .setMinTokenLength(2)\n",
    "            .setToLowercase(true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a225d94-7cdf-47cf-a225-f07f20701f19",
   "metadata": {},
   "source": [
    "## Remover"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bde3b24-33b6-4660-a15e-15d242dd99a2",
   "metadata": {},
   "source": [
    "Pretty straight forward, removes the stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffe8b8c8-11af-4364-ade4-ab80de213c49",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "remover: org.apache.spark.ml.feature.StopWordsRemover = StopWordsRemover: uid=stopWords_8121a1a3402c, numStopWords=596, locale=en_US, caseSensitive=false\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val remover = new StopWordsRemover()\n",
    "            .setInputCol(\"terms\")\n",
    "            .setOutputCol(\"terms_remover\")\n",
    "            .setStopWords(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9eddbf0-cff4-438b-a7d8-43e690a2bec9",
   "metadata": {},
   "source": [
    "## CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ef9b413-dc8e-4b03-939a-0d32825ce31c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cv_model: org.apache.spark.ml.feature.CountVectorizer = cntVec_ab4669ff5784\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val cv_model = new CountVectorizer()\n",
    "            .setInputCol(\"terms_remover\")\n",
    "            .setOutputCol(\"features\")\n",
    "            .setMinDF(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2542dd4f-6208-4cd0-a3ea-aaad436c2f42",
   "metadata": {},
   "source": [
    "## IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc30a0dc-b686-43ef-a1c3-a63dc7b4eca0",
   "metadata": {},
   "source": [
    "This takes the output of the *CountVectorizer* model as input and then scales each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac63363c-19c6-44ce-87e2-5076f0bb9541",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "idf: org.apache.spark.ml.feature.IDF = idf_8f715138721c\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val idf = new IDF()\n",
    "            .setInputCol(\"features\")\n",
    "            .setOutputCol(\"weightedFeatures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b769589-b6ed-408a-a5ba-6edfda177e4f",
   "metadata": {},
   "source": [
    "## Selector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655b18ab-77c2-4c7b-83f1-737fc252a3b0",
   "metadata": {},
   "source": [
    "This is our `ChiSqSelector()`. This selected the top 2000 features according to the Chi-Squared Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53f151ab-4bc6-4ac8-a36b-2f581faaacfe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "selector: org.apache.spark.ml.feature.ChiSqSelector = chiSqSelector_099907002b37\n"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val selector = new ChiSqSelector()\n",
    "          .setNumTopFeatures(2000)\n",
    "          .setFeaturesCol(\"weightedFeatures\")\n",
    "          .setLabelCol(\"label\")\n",
    "          .setOutputCol(\"chiFeatures\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0522fed-38bd-40fe-b841-1b5843407879",
   "metadata": {},
   "source": [
    "## PART 3 - Normalizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a36aa42-dc47-4a31-851a-ee0d218806fc",
   "metadata": {},
   "source": [
    "Normalizes samples individually to unit L(p) norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "afb5df18-4461-40c7-9790-8272ec611970",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normalizer: org.apache.spark.ml.feature.Normalizer = Normalizer: uid=normalizer_ca7d2151cc08, p=2.0\n"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val normalizer = new Normalizer().setInputCol(\"chiFeatures\")\n",
    "                                .setOutputCol(\"normFeatures\") \n",
    "                                .setP(2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac71356-fdf7-454b-9567-8e8334c4c731",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spylon-kernel",
   "language": "scala",
   "name": "spylon-kernel"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "help_links": [
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "0.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
